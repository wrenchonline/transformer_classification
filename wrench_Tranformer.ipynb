{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import argparse\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    " \n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    " \n",
    "# Setup file handler\n",
    "fhandler  = logging.FileHandler('my.log')\n",
    "fhandler.setLevel(logging.DEBUG)\n",
    "fhandler.setFormatter(formatter)\n",
    " \n",
    "# Configure stream handler for the cells\n",
    "chandler = logging.StreamHandler()\n",
    "chandler.setLevel(logging.DEBUG)\n",
    "chandler.setFormatter(formatter)\n",
    " \n",
    "# Add both handlers\n",
    "logger.addHandler(fhandler)\n",
    "logger.addHandler(chandler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    " \n",
    "# Show the handlers\n",
    "logger.handlers\n",
    "\n",
    "\n",
    "titanic_file = '/home/wrench/下载/ML_Tech_Stack/Natural_language_process/myonvif_info.csv'\n",
    "test_file = '/home/wrench/下载/ML_Tech_Stack/Natural_language_process/myonvif_test.csv'\n",
    "#titanic_lines = tf.data.TextLineDataset(titanic_file)\n",
    "#for line in titanic_lines.take(10):\n",
    "#      print(line.numpy())\n",
    "#np.set_printoptions(precision=3, suppress=True) \n",
    "\n",
    "#LABEL_COLUMN = 'brand'\n",
    "#LABELS = [0, 1]\n",
    "#def get_dataset(file_path):\n",
    "#    dataset = tf.data.experimental.make_csv_dataset(\n",
    "#      titanic_file,\n",
    "#      batch_size=1, # 为了示例更容易展示，手动设置较小的值\n",
    "#      label_name=LABEL_COLUMN,\n",
    "#      na_value=\"?\",\n",
    "#      num_epochs=1,\n",
    "#      ignore_errors=True)\n",
    "#    return dataset       \n",
    "#        \n",
    "#raw_train_data = get_dataset(titanic_file)\n",
    "#raw_test_data = get_dataset(test_file)\n",
    "#examples, labels = next(iter(raw_train_data)) # 第一个批次\n",
    "#print(\"EXAMPLES: \\n\", examples, \"\\n\")\n",
    "#print(\"LABELS: \\n\", labels)\n",
    "\n",
    "test_partition = 0.1\n",
    "BATCH_SIZE = 2\n",
    "BUFFER_SIZE = 10000\n",
    "MAX_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_features_vector(features):\n",
    "    \"\"\"Pack the features into a single array.\"\"\"\n",
    "    features = tf.stack(list(features.values()), axis=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", w)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = re.sub(r\"www\", \"\", string)\n",
    "    string = re.sub(r\"onvif\", \"\", string)\n",
    "    string = re.sub(r\"org\", \"\", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Dataset:\n",
    "#    def __init__(\n",
    "#        self,\n",
    "#        filename=\"\",\n",
    "#        vocab_dim=10000,\n",
    "#        max_length=2100,\n",
    "#        buffer_size=20000,\n",
    "#        batch_size=64,\n",
    "#        num_classes=5,\n",
    "#        classes=[],\n",
    "#    ):\n",
    "#        self.input_filename = filename\n",
    "#        self.classes_filename = filename + \".classes\"\n",
    "#        self.train_filename = filename + \".train\"\n",
    "#        self.test_filename = filename + \".test\"\n",
    "#        self.vocabulary_size = vocab_dim\n",
    "#        self.max_length = max_length\n",
    "#        self.batch_size = batch_size\n",
    "#        self.buffer_size = buffer_size\n",
    "#        self.num_classes = num_classes\n",
    "#        self.classes = classes\n",
    "#\n",
    "#    def build_train_test(self, test=0.2):\n",
    "#        \"\"\" This function takes the input file and splits into training and testing \"\"\"\n",
    "#\n",
    "#        labels = {}\n",
    "#\n",
    "#        file_lines = []\n",
    "#        for ix, i in enumerate(open(self.input_filename)):\n",
    "#            i = i.strip().split(\"\\t\")\n",
    "#            labels[i[1]] = True\n",
    "#            file_lines.append(ix)\n",
    "#\n",
    "#        random.shuffle(file_lines)\n",
    "#        test_limit = int(len(file_lines) * test)\n",
    "#\n",
    "#        test_dict = {i: True for i in file_lines[0:test_limit]}\n",
    "#\n",
    "#        fo_test = open(self.test_filename, \"w\")\n",
    "#        fo_train = open(self.train_filename, \"w\")\n",
    "#        for ix, i in enumerate(open(self.input_filename)):\n",
    "#            try:\n",
    "#                assert test_dict[ix]\n",
    "#                fo_test.write(i)\n",
    "#            except:\n",
    "#                fo_train.write(i)\n",
    "#\n",
    "#        fo = open(self.classes_filename, \"w\")\n",
    "#        for i in labels:\n",
    "#            fo.write(i + \"\\n\")\n",
    "#        fo.close()\n",
    "#\n",
    "#    def format_train_test(self):\n",
    "#        filenames = [self.train_filename]\n",
    "#        train_dataset_tf = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "#        train_dataset_tf = train_dataset_tf.flat_map(\n",
    "#            lambda filename: (tf.data.TextLineDataset(filename))\n",
    "#        )\n",
    "#\n",
    "#        filenames = [self.test_filename]\n",
    "#        test_dataset_tf = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "#        test_dataset_tf = test_dataset_tf.flat_map(\n",
    "#            lambda filename: (tf.data.TextLineDataset(filename))\n",
    "#        )\n",
    "#\n",
    "#        return train_dataset_tf, test_dataset_tf\n",
    "#\n",
    "#    def format_dataset(self):\n",
    "#        filenames = [self.train_filename, self.test_filename]\n",
    "#        test_dataset_tf = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "#        test_dataset_tf = test_dataset_tf.flat_map(\n",
    "#            lambda filename: (tf.data.TextLineDataset(filename))\n",
    "#        )\n",
    "#        return test_dataset_tf\n",
    "#\n",
    "#    def tokenizer(self, train_examples,Classlist):\n",
    "##        for examples , labels in  raw_train_data:\n",
    "##             print (examples['context'].numpy())\n",
    "#        self.tokenizer_source = tfds.features.text.SubwordTextEncoder.build_from_corpus( \n",
    "#        (b\"\".join(examples['context'].numpy().tolist()) for examples , labels in  raw_train_data),\n",
    "#        target_vocab_size=2**13,\n",
    "#        )\n",
    "#        self.tokenizer_target = tfds.features.ClassLabel(names=Classlist)\n",
    "#        return self.tokenizer_source, self.tokenizer_target\n",
    "#\n",
    "#    def encode(self, string_Tensor,k_Tensor):\n",
    "##        print('source')\n",
    "##        print(string_Tensor)\n",
    "##        print('target')\n",
    "##        print(k_Tensor)\n",
    "#        source = (\n",
    "#            [self.tokenizer_source.vocab_size]\n",
    "#            + self.tokenizer_source.encode(\n",
    "#                preprocess_sentence(\n",
    "#                    b\"\".join(string_Tensor.numpy().tolist()).decode(\"UTF-8\")\n",
    "#                ).encode()\n",
    "#            )\n",
    "#            + [self.tokenizer_source.vocab_size + 1]\n",
    "#        )\n",
    "#\n",
    "#        target = self.tokenizer_target.encode_example(\n",
    "#            b\"\".join(k_Tensor.numpy().tolist()).decode(\"UTF-8\")\n",
    "#        )\n",
    "#        #这里在下方代码for one_element in train_dataset:  会执行  ，随便查看数据\n",
    "##        print('source')\n",
    "##        print(string_Tensor)\n",
    "##        print('target')\n",
    "##        print(target)\n",
    "#        return source, target\n",
    "#\n",
    "#    def tf_encode(self, string_Tensor,k_Tensor):\n",
    "#        return tf.py_function(self.encode, [string_Tensor,k_Tensor], [tf.int64, tf.int64])\n",
    "#\n",
    "#    def filter_max_length(self, x, y):\n",
    "#        return tf.logical_and(\n",
    "#            tf.size(x) <= self.max_length, tf.size(x) <= self.max_length\n",
    "#        )\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        filename=\"\",\n",
    "        vocab_dim=10000,\n",
    "        max_length=40,\n",
    "        buffer_size=20000,\n",
    "        batch_size=64,\n",
    "        num_classes=5,\n",
    "        classes=[],\n",
    "    ):\n",
    "        self.input_filename = filename\n",
    "        self.classes_filename = filename + \".classes\"\n",
    "        self.train_filename = filename + \".train\"\n",
    "        self.test_filename = filename + \".test\"\n",
    "        self.vocabulary_size = vocab_dim\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_size = buffer_size\n",
    "        self.num_classes = num_classes\n",
    "        self.classes = classes\n",
    "        self.labels_list=['Dahua','Hikvision']\n",
    "\n",
    "    def build_train_test(self, test=0.2):\n",
    "        \"\"\" This function takes the input file and splits into training and testing \"\"\"\n",
    "\n",
    "        labels = {}\n",
    "\n",
    "        file_lines = []\n",
    "        for ix, i in enumerate(open(self.input_filename)):\n",
    "            i = i.strip().split(\"\\t\")\n",
    "            labels[i[1]] = True\n",
    "            file_lines.append(ix)\n",
    "\n",
    "        random.shuffle(file_lines)\n",
    "        test_limit = int(len(file_lines) * test)\n",
    "\n",
    "        test_dict = {i: True for i in file_lines[0:test_limit]}\n",
    "\n",
    "        fo_test = open(self.test_filename, \"w\")\n",
    "        fo_train = open(self.train_filename, \"w\")\n",
    "        for ix, i in enumerate(open(self.input_filename)):\n",
    "            try:\n",
    "                assert test_dict[ix]\n",
    "                fo_test.write(i)\n",
    "            except:\n",
    "                fo_train.write(i)\n",
    "\n",
    "        fo = open(self.classes_filename, \"w\")\n",
    "        for i in labels:\n",
    "            fo.write(i + \"\\n\")\n",
    "        fo.close()\n",
    "\n",
    "    def format_train_test(self):\n",
    "        filenames = [self.train_filename]\n",
    "        train_dataset_tf = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "        train_dataset_tf = train_dataset_tf.flat_map(\n",
    "            lambda filename: (tf.data.TextLineDataset(filename))\n",
    "        )\n",
    "\n",
    "        filenames = [self.test_filename]\n",
    "        test_dataset_tf = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "        test_dataset_tf = test_dataset_tf.flat_map(\n",
    "            lambda filename: (tf.data.TextLineDataset(filename))\n",
    "        )\n",
    "\n",
    "        return train_dataset_tf, test_dataset_tf\n",
    "\n",
    "    def format_dataset(self):\n",
    "        filenames = [self.train_filename, self.test_filename]\n",
    "        test_dataset_tf = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "        test_dataset_tf = test_dataset_tf.flat_map(\n",
    "            lambda filename: (tf.data.TextLineDataset(filename))\n",
    "        )\n",
    "        return test_dataset_tf\n",
    "\n",
    "    def tokenizer(self, train_examples):\n",
    "        self.tokenizer_source = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "            (\n",
    "                preprocess_sentence(pt.numpy().decode(\n",
    "                    \"UTF-8\").split(\"\\t\")[0]).encode()\n",
    "                for pt in train_examples\n",
    "            ),\n",
    "            target_vocab_size=self.vocabulary_size,\n",
    "        )\n",
    "\n",
    "        self.tokenizer_target = tfds.features.ClassLabel(\n",
    "            names_file=self.classes_filename\n",
    "        )\n",
    "\n",
    "        return self.tokenizer_source, self.tokenizer_target\n",
    "\n",
    "    def encode(self, string):\n",
    "        source = (\n",
    "            [self.tokenizer_source.vocab_size]\n",
    "            + self.tokenizer_source.encode(\n",
    "                preprocess_sentence(\n",
    "                    string.numpy().decode(\"UTF-8\").split(\"\\t\")[0]\n",
    "                ).encode()\n",
    "            )\n",
    "            + [self.tokenizer_source.vocab_size + 1]\n",
    "        )\n",
    "\n",
    "        target = self.tokenizer_target.encode_example(\n",
    "            string.numpy().decode(\"UTF-8\").split(\"\\t\")[1]\n",
    "        )\n",
    "\n",
    "        return source, target\n",
    "\n",
    "    def tf_encode(self, string):\n",
    "        return tf.py_function(self.encode, [string], [tf.int64, tf.int64])\n",
    "\n",
    "    def filter_max_length(self, x, y):\n",
    "        return tf.logical_and(\n",
    "            tf.size(x) <= self.max_length, tf.size(x) <= self.max_length\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org type video encoder onvif www onvif org profile streaming onvif www onvif org profile g onvif www onvif org type audio encoder onvif www onvif org hardware ds 2cd2710xyz abcd onvif www onvif org name hikvision 20ds 2cd2710xyz abcd onvif www onvif org location city hangzhou\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name dahua onvif www onvif org hardware ipc hum4101 onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name dahua onvif www onvif org hardware ipc hum4101 onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name dahua onvif www onvif org hardware ipc hum4101 onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name dahua onvif www onvif org hardware ipc hum4101 onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name dahua onvif www onvif org hardware ipc hum4101 onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name dahua onvif www onvif org hardware ipc hum4101 onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name dahua onvif www onvif org hardware ipc hum4101 onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name dahua onvif www onvif org hardware ipc hum4101 onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name dahua onvif www onvif org hardware ipc hum4101 onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name general onvif www onvif org hardware ip camera onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name dahua onvif www onvif org hardware ipc hum4101 onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'onvif www onvif org location country china onvif www onvif org name dahua onvif www onvif org hardware ipc hum4101 onvif www onvif org profile streaming onvif www onvif org type network video transmitter onvif www onvif org extension unique identifier\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'dahua\\t0', shape=(), dtype=string)\n",
      "--------------------\n",
      "tf.Tensor(b'hikvision\\t1', shape=(), dtype=string)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#examples_list = []\n",
    "#\n",
    "#\n",
    "#labels_list=['Dahua','Hikvision']\n",
    "##print(examples)\n",
    "#dataset = Dataset()\n",
    "#\n",
    "#tokenizer_source,tokenizer_target = dataset.tokenizer(raw_train_data ,labels_list)\n",
    "##\n",
    "##\n",
    "##    \n",
    "##print(\"dasdsadas\")\n",
    "#db_train = tf.data.Dataset.from_tensor_slices(\n",
    "#    (\n",
    "#        [examples['context'] for examples ,labels in raw_train_data ],\n",
    "#        [labels for examples ,labels in raw_train_data ]\n",
    "#    )\n",
    "#)\n",
    "#\n",
    "#db_test = tf.data.Dataset.from_tensor_slices(\n",
    "#    (\n",
    "#        [examples['context'] for examples ,labels in raw_test_data ],\n",
    "#        [labels for examples ,labels in raw_test_data ]\n",
    "#    )\n",
    "#)\n",
    "#\n",
    "#\n",
    "#\n",
    "##for (step_idx, (inp, tar)) in enumerate(db_train):\n",
    "##    print(inp)\n",
    "##    print(tar)\n",
    "##    print ('11111111')\n",
    "##    print ('-'*20)\n",
    "#\n",
    "#train_example = db_train.map(dataset.tf_encode)\n",
    "#test_example = db_test.map(dataset.tf_encode)\n",
    "dataset = Dataset(\"/home/wrench/下载/ML_Tech_Stack/Natural_language_process/data_onvif/2/brand\")\n",
    "train_examples, val_examples =  dataset.format_train_test()\n",
    "dataset.build_train_test(test=test_partition)\n",
    "for (step_idx, (inp)) in enumerate(train_examples):\n",
    "    print(inp)\n",
    "    print ('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-01 04:53:27,428 - absl - INFO - SubwordTextEncoder build: trying min_token_count 304\n",
      "2020-03-01 04:53:27,452 - absl - INFO - SubwordTextEncoder build: trying min_token_count 157\n",
      "2020-03-01 04:53:27,468 - absl - INFO - SubwordTextEncoder build: trying min_token_count 83\n",
      "2020-03-01 04:53:27,487 - absl - INFO - SubwordTextEncoder build: trying min_token_count 46\n",
      "2020-03-01 04:53:27,509 - absl - INFO - SubwordTextEncoder build: trying min_token_count 28\n",
      "2020-03-01 04:53:27,522 - absl - INFO - SubwordTextEncoder build: trying min_token_count 19\n",
      "2020-03-01 04:53:27,544 - absl - INFO - SubwordTextEncoder build: trying min_token_count 14\n",
      "2020-03-01 04:53:27,564 - absl - INFO - SubwordTextEncoder build: trying min_token_count 12\n",
      "2020-03-01 04:53:27,579 - absl - INFO - SubwordTextEncoder build: trying min_token_count 11\n"
     ]
    }
   ],
   "source": [
    "tokenizer_source, tokenizer_target = dataset.tokenizer(train_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  25   1  11  30  31   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  25   1  11  30  31   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  25   1  11  30  31   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  25   1  11  30  31   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  25   1  11  30  31   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  25   1  11  30  31   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  25   1  11  30  31   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  25   1  11  30  31   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  25   1  11  30  31   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  25   1  11  30  31   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  25   1  11  30  31   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  29 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288  25 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288  10  23  24   1   9  27   1  11  26  28   1   3   8   1   2  20   7\n",
      "   19   1  22  18  21 289   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 50), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "--------------------\n",
      "tf.Tensor(\n",
      "[[288   2   7   4   1   3   8   1   3 135   1   2  16   4   1  11  14   6\n",
      "    5   1   9  12  17   6   5   1  10  15  13 289   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(1, 50), dtype=int64)\n",
      "tf.Tensor([0], shape=(1,), dtype=int64)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#MAX_LENGTH = 2100\n",
    "#BATCH_SIZE = 32\n",
    "#BUFFER_SIZE = 15000\n",
    "\n",
    "\n",
    "# 训练集\n",
    "#train_dataset = (train_example  # 输出：(英文句子，标签)\n",
    "#                 .filter(dataset.filter_max_length)\n",
    "#                 .shuffle(BUFFER_SIZE) # 将例子随机打乱\n",
    "#                 .padded_batch(BATCH_SIZE, # 将 batch 里的序列都 pad 到同样长度\n",
    "#                              padded_shapes=([MAX_LENGTH], []))\n",
    "#                 .prefetch(tf.data.experimental.AUTOTUNE)) # 加速\n",
    "## 验证集\n",
    "#val_dataset = (test_example\n",
    "#               .filter(dataset.filter_max_length)\n",
    "#               .shuffle(BUFFER_SIZE)\n",
    "#               .padded_batch(BATCH_SIZE,\n",
    "#                             padded_shapes=([MAX_LENGTH], [])))\n",
    "train_dataset = train_examples.map(dataset.tf_encode)\n",
    "train_dataset = train_dataset.filter(dataset.filter_max_length)\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([MAX_LENGTH], [])\n",
    ")\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_examples.map(dataset.tf_encode)\n",
    "val_dataset = val_dataset.filter(dataset.filter_max_length).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([MAX_LENGTH], [])\n",
    ")\n",
    "\n",
    "for (step_idx, (inp, tar)) in enumerate(train_dataset):\n",
    "    print(inp)\n",
    "    print(tar)\n",
    "    print ('-'*20)\n",
    "#    x_point, y_point = tf.convert_to_tensor([inp]), tf.convert_to_tensor([tar])\n",
    "#    print(x_point.get_shape())\n",
    "#    print(y_point.get_shape())\n",
    "#    print ('222222222')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2. Masking\n",
    "遮掩（masking）可以说是在实践 Transformer 时最重要却也最容易被搞砸的一环。\n",
    "它让 Transformer 在进行自注意力机制（Self-Attention Mechanism）时不至于偷看到不该看的内容。\n",
    "在 Transformer 里有两种 masks：\n",
    "1. padding mask\n",
    "2. look ahead mask\n",
    "\n",
    "Padding mask 是让 Transformer 用来识别序列实际的内容到哪里。此遮掩负责的就是将序列中被补 0 的地方（也就是 &#60;pad&#62;）的位置盖住，让 Transformer 可以避免「关注」到这些位置。\n",
    "\n",
    "Look ahead mask 是用来确保 Decoder 在进行自注意力机制时每个子词只会「往前看」：关注（包含）自己之前的子词，不会不小心关注「未來」Decoder 产生的子词。\n",
    "\n",
    "不管是哪一种 Masking 向量，那些值为 1 的位置就是遮掩存在的地方。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_padding_mask(seq):\n",
    "#    # padding mask 的工作就是把索引序列中為 0 的位置設為 1\n",
    "#    mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
    "#    return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    \"\"\"\n",
    "    Mask all the pad tokens in the batch of sequence. It ensures that the model\n",
    "    does not treat padding as the input. The mask indicates where pad value 0\n",
    "    is present: it outputs a 1 at those locations, and a 0 otherwise.\n",
    "    \"\"\"\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions so that we can add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    \"\"\"\n",
    "    The look-ahead mask is used to mask the future tokens in a sequence. In other words,\n",
    "    the mask indicates which entries should not be used.\n",
    "    This means that to predict the third word, only the first and second word will be used.\n",
    "    Similarly to predict the fourth word, only the first, second and the third word will\n",
    "    be used and so on.\n",
    "    \"\"\"\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    # dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    # look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[0])\n",
    "    # dec_target_padding_mask = create_padding_mask(tar)\n",
    "    # combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    \"\"\"\n",
    "    Since this model doesn't contain any recurrence or convolution, positional\n",
    "    encoding is added to give the model some information about the relative\n",
    "    position of the words in the sentence.\n",
    "    The positional encoding vector is added to the embedding vector. Embeddings\n",
    "    represent a token in a d-dimensional space where tokens with similar meaning\n",
    "    will be closer to each other. But the embeddings do not encode the relative\n",
    "    position of words in a sentence. So after adding the positional encoding,\n",
    "    words will be closer to each other based on the similarity of their meaning\n",
    "    and their position in the sentence, in the d-dimensional space\n",
    "    \"\"\"\n",
    "\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    sines = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    cosines = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
    "\n",
    "    pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 loss_Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=40000):\n",
    "        \"\"\"\n",
    "            Use the Adam optimizer with a custom learning\n",
    "            rate scheduler according to the formula in\n",
    "            the paper.\n",
    "        \"\"\"\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "def loss_function(real,pred):\n",
    "    \"\"\"\n",
    "    Since the target sequences are padded,\n",
    "    it is important to apply a padding mask when\n",
    "    calculating the loss.\n",
    "    \"\"\"\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这里是文本分类，只用到编码器，所以不需要mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention\n",
    "\n",
    "首先，每个 $query_i$ / $key_i$ / $value_i$ 向量是由输入 $x_i$ 乘以矩阵 $M_q$ / $M_k$ / $M_v$ 得到的。\n",
    "\n",
    "注意力机制 Attention 就是拿一个查询向量（query）去跟一组键值对（key-value）做运算，最后产生一个输出。\n",
    "\n",
    "我们会把这些 query 向量拼成 Q 矩阵，key 向量拼成 K 矩阵，value 向量拼成 V 矩阵，然后利用矩阵运算运算同时让多个查询跟一组 key-value 做运算，从而最大化计算效率。\n",
    "\n",
    "而不管是查询 query、键 key、值 value 还是输出，全部都是向量。输出 $output_i$ 是各个 value 的加权平均，权重向量即为 $softmax(\\frac{Qk_i^{T}}{\\sqrt{d_k}})$ ，即是对应输入 $x_i$ 的查询向量 $query_i$ 与每个键 $key_j$ 计算匹配程度。匹配程度越高，则 $value_i$ 被提取的比例就越大。（[论文原文](https://arxiv.org/abs/1706.03762)称此匹配度计算的函数为 compatibility function。）公式中的 $d_k$ 是指键向量 k 的维度。\n",
    "\n",
    "$$ Attention(Q,K,V) = softmax(\\frac{QK^{T}}{\\sqrt{d_k}}) V $$\n",
    "\n",
    "softmax 函数作用于 logits score 向量 $y$ 的每一个分量 $y_i$，对应获得其 probabilities。\n",
    "\n",
    "$$ softmax(y_i) = \\frac{e^{y_i}}{\\sum_j e^{y_j}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    The mask has different shapes depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition.\n",
    "    Args:\n",
    "        q: query shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth)\n",
    "        mask: Float tensor with shape broadcastable\n",
    "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    Returns:\n",
    "        output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    # (..., seq_len_q, seq_len_k)\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += mask * -1e9\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(\n",
    "        scaled_attention_logits, axis=-1\n",
    "    )  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_v, depth)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Multi-Head Attention\n",
    "\n",
    "**每个 Head 各司其职：你看你的，我看我的。**\n",
    "\n",
    "将 Q、K、V 这三个张量先分别转换到 d_model 维空间，再将其拆成多个比较低维的 depth 维张量 N 次，然后将这些产生的小 q、小 k 以及小 v 分別扔进注意力函数得到 N 个结果。接著将这 N 个 head 的结果串接起來，最后通过一个线性转换就能得到 multi-head attention 的输出。\n",
    "\n",
    "为了实现 multi-head attention，得先能把一个 head 拆成多个 heads。而这实际上就是把一个 d_model 维的向量拆成 num_heads 个 depth 维的向量，使得：num_heads * depth = d_model。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_heads_bak(x, d_model, num_heads):\n",
    "    # x.shape: (batch_size, seq_len, d_model)\n",
    "    batch_size = tf.shape(x)[0]\n",
    "\n",
    "    # 确保维度 `d_model` 可以被平分成 `num_heads` 个 `depth` 维度，即整除\n",
    "    assert d_model % num_heads == 0\n",
    "    depth = d_model // num_heads  # 这是分成多头以后每个向量的维度\n",
    "\n",
    "    # 将最后一个 d_model 维度分成 num_heads 个 depth 维度\n",
    "    # 最后一个维度变成两个维度，张量 x 从 3 维到 4 维\n",
    "    # (batch_size, seq_len, num_heads, depth)\n",
    "    reshaped_x = tf.reshape(x, shape=(batch_size, -1, num_heads, depth))\n",
    "\n",
    "    # 将 head 的维度拉伸使得最后两个维度为子词以及其对应的 depth 向量\n",
    "    # (batch_size, num_heads, seq_len, depth)\n",
    "    output = tf.transpose(reshaped_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-Head Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len_q, depth)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        # (batch_size, num_heads, seq_len_k, depth)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        # (batch_size, num_heads, seq_len_v, depth)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_v, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask\n",
    "        )\n",
    "\n",
    "        scaled_attention = tf.transpose(\n",
    "            scaled_attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len_v, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(\n",
    "            scaled_attention, (batch_size, -1, self.d_model)\n",
    "        )  # (batch_size, seq_len_v, d_model)\n",
    "\n",
    "        # (batch_size, seq_len_v, d_model)\n",
    "        output = self.dense(concat_attention)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Transformer\n",
    "\n",
    "- Transformer\n",
    "    - Encoder\n",
    "        - 输入 Embedding\n",
    "        - 位置 Encoding\n",
    "        - N 个 Encoder layers\n",
    "        - sub-layer 1: Encoder 自注意力机制\n",
    "        - sub-layer 2: Feed Forward\n",
    "    - Final Dense Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1. Position-wise Feed-Forward Networks\n",
    "\n",
    "建立 Transformer 里 Encoder / Decoder layer 都会使用到的 Feed Forward 组件。\n",
    "\n",
    "此函数在每次被 call 的时候都会回传一组新的全连接前馈神经网络（Fully-connected Feed Forward Network，FFN），其输入张量与输出张量的最后一个维度皆为 d_model，而在 FFN 中间层的维度則為 dff。一般会让 dff 大于 d_model，让 FFN 从输入的 d_model 维度里提取些有用的信息。在论文中 d_model 为 512，dff 则为 4 倍的 2048。两个都是可以调整的超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            # (batch_size, seq_len, dff)\n",
    "            tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(d_model),  # (batch_size, seq_len, d_model)\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2. Encoder layer\n",
    "\n",
    "有了 Multi-Head Attention（MHA）以及 Feed-Forward Network（FFN），就可以完成第一个 Encoder layer 了。\n",
    "\n",
    "一个 Encoder layer 里会有两个 sub-layers，分別为 MHA 以及 FFN。在 Add & Norm 步骤里，每个 sub-layer 会有一个残差廉洁（residual connection）来帮助减缓梯度消失（Gradient Vanishing）的问题。接着两个 sub-layers 都会针对最后一维 d_model 做 layer normalization，将 batch 里每个子词的输出彼此独立地做转换，使其均值和标准差分別靠近 0 和 1 之后输出。\n",
    "\n",
    "另外在将 sub-layer 的输出与其输入相加之前，还会做 regularization，对该 sub-layer 的输出使用 dropout。\n",
    "(PS:这里不需要mask来进行遮掩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, attention_weights = self.mha(\n",
    "            x, x, x, mask\n",
    "        )  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        # (batch_size, input_seq_len, d_model)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(\n",
    "            out1 + ffn_output\n",
    "        )  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.5. Encoder\n",
    "\n",
    "Encoder 里主要包含了以下 3 个组件：\n",
    "\n",
    "1. 输入的词嵌入层\n",
    "2. 位置编码\n",
    "3. N 个 Encoder layers\n",
    "\n",
    "由于大部分的工作都在 Encoder layer 里执行了，因此 Encoder 部分代码比较简单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
    "\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        attention_weights = {}\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1 = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        attention_weights[\"decoder_layer{}_block1\".format(i + 1)] = block1\n",
    "\n",
    "        return x, attention_weights  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.6  Modeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        dff,\n",
    "        input_vocab_size,\n",
    "        target_vocab_size,\n",
    "        rate=0.1,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            num_layers, d_model, num_heads, dff, input_vocab_size, rate\n",
    "        )\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.final_layer = tf.keras.layers.Dense(\n",
    "            64)\n",
    "        self.dense_1 = tf.keras.layers.Dense(\n",
    "            target_vocab_size, activation=\"softmax\")\n",
    "        # self.out = tf.nn.softmax(target_vocab_size)\n",
    "        #        self.dense_1 = tf.keras.layers.Dense(target_vocab_size, activation=\"softmax\")\n",
    "    def call(\n",
    "        self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask\n",
    "    ):\n",
    "\n",
    "        enc_output, attention_weights = self.encoder(\n",
    "            inp, training, enc_padding_mask\n",
    "        )  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        predictions = self.final_layer(\n",
    "            enc_output\n",
    "        )  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        embeddings = self.flatten(predictions)\n",
    "        predictions = self.dense_1(embeddings)\n",
    "\n",
    "        return predictions, embeddings, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perc = 100\n",
    "num_layers = 1 \n",
    "d_model = 12\n",
    "dff = 32 \n",
    "num_heads = 1\n",
    "input_vocab_size = tokenizer_source.vocab_size + 2\n",
    "target_vocab_size = tokenizer_target.num_classes\n",
    "dropout_rate =0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个 Transformer 有 1 层 Encoder / Decoder layers\n",
      "d_model: 12\n",
      "num_heads: 1\n",
      "dff: 32\n",
      "input_vocab_size: 290\n",
      "target_vocab_size: 2\n",
      "dropout_rate: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff, \n",
    "                          input_vocab_size, target_vocab_size, dropout_rate)\n",
    "\n",
    "print(f\"\"\"这个 Transformer 有 {num_layers} 层 Encoder / Decoder layers\n",
    "d_model: {d_model}\n",
    "num_heads: {num_heads}\n",
    "dff: {dff}\n",
    "input_vocab_size: {input_vocab_size}\n",
    "target_vocab_size: {target_vocab_size}\n",
    "dropout_rate: {dropout_rate}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "        name=\"train_accuracy\")\n",
    "test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "        name=\"test_accuracy\")\n",
    "\n",
    "@tf.function # 利用 TensorFlow 将 eager code 优化并加快运算\n",
    "def train_step(inp, tar):\n",
    "    # 建立 3 个遮掩\n",
    "    logger.debug(\"input: {}\".format(inp.shape))\n",
    "    logger.debug(\"target: {}\".format(tar.shape))\n",
    "    \n",
    "    enc_padding_mask = create_masks(inp, tar)\n",
    "\n",
    "    # 记录 Transformer 的所有运算过程以方便之后做梯度下降\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 注意是输入 `tar_inp` 而非 `tar`，记得将 `training` 参数设定为 True\n",
    "        predictions, enc_output ,_ = transformer(inp, tar, \n",
    "                                     True, \n",
    "                                     enc_padding_mask, \n",
    "                                     None, \n",
    "                                     None)\n",
    "        # 跟影片中显示的相同，计算左移一個字的序列跟模型预测分布之间的差异，当作 loss\n",
    "        loss = loss_function(tar, predictions)\n",
    "\n",
    "    # 取出梯度并呼叫前面定义的 Adam optimizer 以便更新 Transformer 里可训练的参数\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    # （非必要）将 loss 以及训练 acc 记录到 TensorBoard 上\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar, predictions)\n",
    "    \n",
    "    logger.debug(\"predictions: {}\".format(predictions.shape))\n",
    "    logger.debug(\"tar_real: {}\".format(tar.shape))\n",
    "    logger.debug(\"enc_output: {}\".format(enc_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.7. Optimizer\n",
    "\n",
    "这里跟[原论文](https://arxiv.org/abs/1706.03762)保持一致，使用 Adam Optimizer 以及自定义的 learning rate scheduler\n",
    "\n",
    "$$ learning\\_rate = d_{model}^5 \\times \\min{step\\_num^{-0.5}, step\\_num \\times warmup\\_steps^{-1.5}} $$\n",
    "\n",
    "这个 schedule 让训练过程的前 warmup_steps 的 learning rate 线性增加，之后则跟步骤数 step_num 的反平方根成比例下降。\n",
    "\n",
    "可以参考[ TensorFlow 官方教学的实现](https://www.tensorflow.org/beta/tutorials/text/transformer?authuser=1#optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将自定义的 learning rate schdeule 输入 Adam opt.\n",
    "# Adam opt. 的参数都跟原论文相同\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. checkpoint\n",
    "\n",
    "设置 checkpoint 来定期存储 / 读取模型及 optimizer 是必备的。\n",
    "\n",
    "本节会定义一个 checkpoint 路径，此路径包含了各种超参数的信息，方便之后比较不同试验的结果并载入已训练的进度。\n",
    "\n",
    "同时也需要一个 checkpoint manager 来做所有跟存储模型模有关的杂事，并只保留最新 5 个 checkpoints 以避免占用太多空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "没找到 checkpoint，从头训练。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "output_dir = \"/home/wrench/data/NMT\"\n",
    "checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
    "log_dir = os.path.join(output_dir, 'logs')\n",
    "# 方便比较不同实验 / 不同超参数设定的结果\n",
    "run_id = f\"{num_layers}layers_{d_model}d_{num_heads}heads_{dff}dff_{train_perc}train_perc\"\n",
    "checkpoint_path = os.path.join(checkpoint_path, run_id)\n",
    "log_dir = os.path.join(log_dir, run_id)\n",
    "\n",
    "# tf.train.Checkpoint 可以帮我们把想要存下來的东西整合起來，方便存储与读取\n",
    "# 一般來说会存下模型以及 optimizer 的状态\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, \n",
    "                           optimizer=optimizer)\n",
    "\n",
    "# ckpt_manager 会去 checkpoint_path 看有没有符合 ckpt 里定义的东西\n",
    "# 存档的时候只保留最近 5 次 checkpoints，其他自动删除\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 如果在 checkpoint 路径上有发现档案就读进来\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "\n",
    "    # 用來确认之前训练多少 epochs 了\n",
    "    last_epoch = int(ckpt_manager.latest_checkpoint.split(\"-\")[-1])\n",
    "    print(f'已读取最新的 checkpoint，模型已训练 {last_epoch} epochs。')\n",
    "else:\n",
    "    last_epoch = 0\n",
    "    print(\"没找到 checkpoint，从头训练。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def test_acc(batch=32, test_dataset=[], transformer=[], test_accuracy=[], test_loss=[]):\n",
    "    real = []\n",
    "    pred = []\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(test_dataset):\n",
    "        #logger.debug(\"input: {}\".format(inp.shape))\n",
    "        #logger.debug(\"target: {}\".format(tar.shape))\n",
    "\n",
    "        enc_padding_mask = create_masks(inp, tar)\n",
    "\n",
    "        predictions, _, _ = transformer(\n",
    "            inp, tar, False, enc_padding_mask, None, None)\n",
    "        #logger.debug(\"predictions: {}\".format(predictions.shape))\n",
    "        #logger.debug(\"tar_real: {}\".format(tar.shape))\n",
    "\n",
    "        test_accuracy(tar, predictions)\n",
    "        test_loss(loss_function(tar, predictions))\n",
    "\n",
    "        tar = tf.Variable(tar)\n",
    "        predictions = tf.Variable(predictions)\n",
    "\n",
    "        real += tar.numpy().tolist()\n",
    "        pred += [i for i in np.argmax(predictions.numpy(), axis=1)]\n",
    "\n",
    "        test_accuracy(tar, predictions)\n",
    "        test_loss(loss_function(tar, predictions))\n",
    "\n",
    "    # print(classification_report(real, pred))\n",
    "    F1 = f1_score(real, pred, average='macro')\n",
    "\n",
    "    return F1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "此超参数組合的 Transformer 已经训练 0 epochs。\n",
      "剩余 epochs：-50\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc15438ce80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7fc157822df0> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-01 04:53:28,936 - root - DEBUG - input: (2, 50)2020-03-01 04:53:30,306 - tensorflow - WARNING - AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc15438ce80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7fc157822df0> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc15438ce80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7fc157822df0> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-03-01 04:53:30,771 - root - DEBUG - target: (2,)\n",
      "2020-03-01 04:53:31,611 - root - DEBUG - predictions: (2, 2)\n",
      "2020-03-01 04:53:31,623 - root - DEBUG - tar_real: (2,)\n",
      "2020-03-01 04:53:31,635 - root - DEBUG - enc_output: (2, 3200)\n",
      "2020-03-01 04:53:31,664 - root - DEBUG - input: (2, 50)\n",
      "2020-03-01 04:53:31,676 - root - DEBUG - target: (2,)\n",
      "2020-03-01 04:53:31,885 - root - DEBUG - predictions: (2, 2)\n",
      "2020-03-01 04:53:31,897 - root - DEBUG - tar_real: (2,)\n",
      "2020-03-01 04:53:31,910 - root - DEBUG - enc_output: (2, 3200)\n",
      "2020-03-01 04:53:32,108 - root - DEBUG - input: (1, 50)\n",
      "2020-03-01 04:53:32,119 - root - DEBUG - target: (1,)\n",
      "2020-03-01 04:53:32,325 - root - DEBUG - predictions: (1, 2)\n",
      "2020-03-01 04:53:32,336 - root - DEBUG - tar_real: (1,)\n",
      "2020-03-01 04:53:32,349 - root - DEBUG - enc_output: (1, 3200)\n",
      "/home/wrench/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Test Loss 0.1455 Accuracy 0.3125 F1 0.2381\n",
      "Saving checkpoint for test epoch 1 at /home/wrench/data/NMT/checkpoints/1layers_12d_1heads_32dff_100train_perc/ckpt-1\n",
      "test Time taken for 1 epoch: 4.378221273422241 secs\n",
      "\n",
      "Epoch 1 Train Loss 0.2401 Accuracy 0.4172\n",
      "Time taken for 1 epoch: 4.379403829574585 secs\n",
      "\n",
      "Epoch 2 Test Loss 0.1445 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 2 Train Loss 0.2617 Accuracy 0.3907\n",
      "Time taken for 1 epoch: 0.1533496379852295 secs\n",
      "\n",
      "Epoch 3 Test Loss 0.1430 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 3 Train Loss 0.2501 Accuracy 0.4371\n",
      "Time taken for 1 epoch: 0.15086627006530762 secs\n",
      "\n",
      "Epoch 4 Test Loss 0.1421 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 4 Train Loss 0.2540 Accuracy 0.4106\n",
      "Time taken for 1 epoch: 0.14279890060424805 secs\n",
      "\n",
      "Epoch 5 Test Loss 0.1381 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 5 Train Loss 0.2415 Accuracy 0.4106\n",
      "Time taken for 1 epoch: 0.14506244659423828 secs\n",
      "\n",
      "Epoch 6 Test Loss 0.1358 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 6 Train Loss 0.2674 Accuracy 0.3974\n",
      "Time taken for 1 epoch: 0.14159274101257324 secs\n",
      "\n",
      "Epoch 7 Test Loss 0.1343 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 7 Train Loss 0.2544 Accuracy 0.3974\n",
      "Time taken for 1 epoch: 0.1446518898010254 secs\n",
      "\n",
      "Epoch 8 Test Loss 0.1327 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 8 Train Loss 0.2478 Accuracy 0.3974\n",
      "Time taken for 1 epoch: 0.14253473281860352 secs\n",
      "\n",
      "Epoch 9 Test Loss 0.1316 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 9 Train Loss 0.2497 Accuracy 0.3974\n",
      "Time taken for 1 epoch: 0.14928293228149414 secs\n",
      "\n",
      "Epoch 10 Test Loss 0.1320 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 10 Train Loss 0.2517 Accuracy 0.3907\n",
      "Time taken for 1 epoch: 0.15023040771484375 secs\n",
      "\n",
      "Epoch 11 Test Loss 0.1342 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 11 Train Loss 0.2557 Accuracy 0.3907\n",
      "Time taken for 1 epoch: 0.14817333221435547 secs\n",
      "\n",
      "Epoch 12 Test Loss 0.1335 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 12 Train Loss 0.2533 Accuracy 0.3974\n",
      "Time taken for 1 epoch: 0.14629411697387695 secs\n",
      "\n",
      "Epoch 13 Test Loss 0.1340 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 13 Train Loss 0.2621 Accuracy 0.3907\n",
      "Time taken for 1 epoch: 0.15699505805969238 secs\n",
      "\n",
      "Epoch 14 Test Loss 0.1324 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 14 Train Loss 0.2228 Accuracy 0.3974\n",
      "Time taken for 1 epoch: 0.14664387702941895 secs\n",
      "\n",
      "Epoch 15 Test Loss 0.1350 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 15 Train Loss 0.2626 Accuracy 0.3974\n",
      "Time taken for 1 epoch: 0.14776039123535156 secs\n",
      "\n",
      "Epoch 16 Test Loss 0.1400 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 16 Train Loss 0.2542 Accuracy 0.4040\n",
      "Time taken for 1 epoch: 0.15056920051574707 secs\n",
      "\n",
      "Epoch 17 Test Loss 0.1395 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 17 Train Loss 0.2444 Accuracy 0.4172\n",
      "Time taken for 1 epoch: 0.14805316925048828 secs\n",
      "\n",
      "Epoch 18 Test Loss 0.1378 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 18 Train Loss 0.2420 Accuracy 0.4636\n",
      "Time taken for 1 epoch: 0.14838409423828125 secs\n",
      "\n",
      "Epoch 19 Test Loss 0.1355 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 19 Train Loss 0.2411 Accuracy 0.4172\n",
      "Time taken for 1 epoch: 0.15160250663757324 secs\n",
      "\n",
      "Epoch 20 Test Loss 0.1414 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 20 Train Loss 0.2494 Accuracy 0.4437\n",
      "Time taken for 1 epoch: 0.1491529941558838 secs\n",
      "\n",
      "Epoch 21 Test Loss 0.1387 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 21 Train Loss 0.2420 Accuracy 0.4172\n",
      "Time taken for 1 epoch: 0.14773035049438477 secs\n",
      "\n",
      "Epoch 22 Test Loss 0.1394 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 22 Train Loss 0.2355 Accuracy 0.4172\n",
      "Time taken for 1 epoch: 0.14940500259399414 secs\n",
      "\n",
      "Epoch 23 Test Loss 0.1331 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 23 Train Loss 0.2186 Accuracy 0.4305\n",
      "Time taken for 1 epoch: 0.14661812782287598 secs\n",
      "\n",
      "Epoch 24 Test Loss 0.1396 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 24 Train Loss 0.2296 Accuracy 0.3974\n",
      "Time taken for 1 epoch: 0.15132713317871094 secs\n",
      "\n",
      "Epoch 25 Test Loss 0.1326 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 25 Train Loss 0.2113 Accuracy 0.4636\n",
      "Time taken for 1 epoch: 0.15021991729736328 secs\n",
      "\n",
      "Epoch 26 Test Loss 0.1368 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 26 Train Loss 0.2182 Accuracy 0.4172\n",
      "Time taken for 1 epoch: 0.15367960929870605 secs\n",
      "\n",
      "Epoch 27 Test Loss 0.1433 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 27 Train Loss 0.2326 Accuracy 0.4768\n",
      "Time taken for 1 epoch: 0.15303993225097656 secs\n",
      "\n",
      "Epoch 28 Test Loss 0.1358 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 28 Train Loss 0.2173 Accuracy 0.5166\n",
      "Time taken for 1 epoch: 0.15060758590698242 secs\n",
      "\n",
      "Epoch 29 Test Loss 0.1332 Accuracy 0.3125 F1 0.2381\n",
      "Epoch 29 Train Loss 0.2196 Accuracy 0.4371\n",
      "Time taken for 1 epoch: 0.150770902633667 secs\n",
      "\n",
      "Epoch 30 Test Loss 0.1478 Accuracy 0.9375 F1 0.9307\n",
      "Saving checkpoint for test epoch 30 at /home/wrench/data/NMT/checkpoints/1layers_12d_1heads_32dff_100train_perc/ckpt-2\n",
      "test Time taken for 1 epoch: 0.16094684600830078 secs\n",
      "\n",
      "Epoch 30 Train Loss 0.2292 Accuracy 0.5563\n",
      "Time taken for 1 epoch: 0.1619100570678711 secs\n",
      "\n",
      "Epoch 31 Test Loss 0.1346 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 31 Train Loss 0.2059 Accuracy 0.6623\n",
      "Time taken for 1 epoch: 0.1474931240081787 secs\n",
      "\n",
      "Epoch 32 Test Loss 0.1396 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 32 Train Loss 0.2164 Accuracy 0.6159\n",
      "Time taken for 1 epoch: 0.14751505851745605 secs\n",
      "\n",
      "Epoch 33 Test Loss 0.1369 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 33 Train Loss 0.2082 Accuracy 0.7020\n",
      "Time taken for 1 epoch: 0.1544971466064453 secs\n",
      "\n",
      "Epoch 34 Test Loss 0.1327 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 34 Train Loss 0.1851 Accuracy 0.7219\n",
      "Time taken for 1 epoch: 0.15184259414672852 secs\n",
      "\n",
      "Epoch 35 Test Loss 0.1333 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 35 Train Loss 0.1978 Accuracy 0.7152\n",
      "Time taken for 1 epoch: 0.15173101425170898 secs\n",
      "\n",
      "Epoch 36 Test Loss 0.1327 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 36 Train Loss 0.1939 Accuracy 0.7483\n",
      "Time taken for 1 epoch: 0.14841032028198242 secs\n",
      "\n",
      "Epoch 37 Test Loss 0.1357 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 37 Train Loss 0.1823 Accuracy 0.7881\n",
      "Time taken for 1 epoch: 0.152052640914917 secs\n",
      "\n",
      "Epoch 38 Test Loss 0.1314 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 38 Train Loss 0.1773 Accuracy 0.7815\n",
      "Time taken for 1 epoch: 0.15096545219421387 secs\n",
      "\n",
      "Epoch 39 Test Loss 0.1315 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 39 Train Loss 0.1781 Accuracy 0.8212\n",
      "Time taken for 1 epoch: 0.15275883674621582 secs\n",
      "\n",
      "Epoch 40 Test Loss 0.1300 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 40 Train Loss 0.1689 Accuracy 0.8411\n",
      "Time taken for 1 epoch: 0.14940786361694336 secs\n",
      "\n",
      "Epoch 41 Test Loss 0.1298 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 41 Train Loss 0.1602 Accuracy 0.8344\n",
      "Time taken for 1 epoch: 0.15262484550476074 secs\n",
      "\n",
      "Epoch 42 Test Loss 0.1292 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 42 Train Loss 0.1577 Accuracy 0.8146\n",
      "Time taken for 1 epoch: 0.1508769989013672 secs\n",
      "\n",
      "Epoch 43 Test Loss 0.1297 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 43 Train Loss 0.1659 Accuracy 0.8212\n",
      "Time taken for 1 epoch: 0.15108323097229004 secs\n",
      "\n",
      "Epoch 44 Test Loss 0.1294 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 44 Train Loss 0.1572 Accuracy 0.8411\n",
      "Time taken for 1 epoch: 0.15193819999694824 secs\n",
      "\n",
      "Epoch 45 Test Loss 0.1292 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 45 Train Loss 0.1616 Accuracy 0.8344\n",
      "Time taken for 1 epoch: 0.1505589485168457 secs\n",
      "\n",
      "Epoch 46 Test Loss 0.1292 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 46 Train Loss 0.1721 Accuracy 0.8344\n",
      "Time taken for 1 epoch: 0.14932990074157715 secs\n",
      "\n",
      "Epoch 47 Test Loss 0.1292 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 47 Train Loss 0.1558 Accuracy 0.8477\n",
      "Time taken for 1 epoch: 0.15078067779541016 secs\n",
      "\n",
      "Epoch 48 Test Loss 0.1292 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 48 Train Loss 0.1602 Accuracy 0.8477\n",
      "Time taken for 1 epoch: 0.15187740325927734 secs\n",
      "\n",
      "Epoch 49 Test Loss 0.1291 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 49 Train Loss 0.1610 Accuracy 0.8477\n",
      "Time taken for 1 epoch: 0.15190458297729492 secs\n",
      "\n",
      "Epoch 50 Test Loss 0.1291 Accuracy 0.9375 F1 0.9307\n",
      "Epoch 50 Train Loss 0.1488 Accuracy 0.8477\n",
      "Time taken for 1 epoch: 0.14934468269348145 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "EPOCHS = 50\n",
    "\n",
    "print(f\"此超参数組合的 Transformer 已经训练 {last_epoch} epochs。\")\n",
    "print(f\"剩余 epochs：{min(0, last_epoch - EPOCHS)}\")\n",
    "\n",
    "# 用来输入信息到 TensorBoard（非必要但十分推荐）\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "# training loop\n",
    "best_test_acc = 0\n",
    "best_test_f1 = 0\n",
    "# 比对设定的 `EPOCHS` 以及已训练的 `last_epoch` 来决定还要训练多少 epochs\n",
    "for epoch in range(last_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    # 重置记录 TensorBoard 的 metrics\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "   \n",
    "    # 一个 epoch 就是把定义的训练数据集一个一个 batch 地拿出来处理，直到看完整个数据集\n",
    "    for (step_idx, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp=inp,tar=tar)\n",
    "\n",
    "    # 每个 epoch 完成就存一次档    \n",
    "#    if (epoch + 1) % 1 == 0:\n",
    "#        ckpt_save_path = ckpt_manager.save()\n",
    "#        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "    test_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_f1 = test_acc(\n",
    "        batch=2,\n",
    "        test_dataset=val_dataset,\n",
    "        transformer=transformer,\n",
    "        test_accuracy=test_accuracy,\n",
    "        test_loss=test_loss,\n",
    "        )    \n",
    "    print(\n",
    "            \"Epoch {} Test Loss {:.4f} Accuracy {:.4f} F1 {:.4f}\".format(\n",
    "                epoch + 1, test_loss.result(), test_accuracy.result(), test_f1\n",
    "            )\n",
    "        )\n",
    "    if best_test_f1 < test_accuracy.result():\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print(\n",
    "            \"Saving checkpoint for test epoch {} at {}\".format(\n",
    "                epoch + 1, ckpt_save_path)\n",
    "            )\n",
    "        best_test_f1 = test_accuracy.result()\n",
    "        print(\"test Time taken for 1 epoch: {} secs\\n\".format(time.time() - start))        \n",
    "\n",
    "    # 将 loss 以及 accuracy 写到 TensorBoard 上\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar(\"train_loss\", train_loss.result(), step=epoch + 1)\n",
    "        tf.summary.scalar(\"train_acc\", train_accuracy.result(), step=epoch + 1)\n",
    "\n",
    "    print('Epoch {} Train Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                        train_loss.result(), \n",
    "                                                        train_accuracy.result()))\n",
    "    print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n",
      "tf.Tensor([7.2733146e-06 9.9999273e-01], shape=(2,), dtype=float32)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int32)\n",
      "[9.9999273e-01 7.2733146e-06]\n",
      "[{'score': 0.9999927282333374, 'label': '0'}, {'score': 7.273314622580074e-06, 'label': '1'}]\n",
      "[[29  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n",
      "tf.Tensor([0.00221491 0.9977851 ], shape=(2,), dtype=float32)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int32)\n",
      "[0.9977851  0.00221491]\n",
      "[{'score': 0.9977850914001465, 'label': '0'}, {'score': 0.0022149106953293085, 'label': '1'}]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def evaluate(inp_sentence,tokenizer_source, tokenizer_target, transformer):\n",
    "    \n",
    "    inp = [tokenizer_source.encode(inp_sentence)]\n",
    "    inp = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        inp, maxlen=50, padding=\"post\"\n",
    "    )\n",
    "    print(inp)\n",
    "    # inp = tf.expand_dims(inp, 0)\n",
    "    enc_padding_mask = create_masks(inp, None)\n",
    "\n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, _, attention_weights = transformer(\n",
    "        inp, None, False, enc_padding_mask, None, None\n",
    "    )\n",
    "\n",
    "    predictions = tf.squeeze(predictions, axis=0)\n",
    "    print(predictions)\n",
    "    predictions_index = tf.cast(\n",
    "        tf.argsort(predictions, axis=-1, direction=\"DESCENDING\"), tf.int32\n",
    "    )\n",
    "    print(predictions_index)\n",
    "    predictions = predictions.numpy()[predictions_index.numpy()]\n",
    "    print(predictions)\n",
    "    _pred = [\n",
    "        {\"score\": float(i), \"label\": tokenizer_target.int2str(j.numpy())}\n",
    "        for i, j in zip(predictions, predictions_index)\n",
    "    ][:2]\n",
    "\n",
    "    return _pred, attention_weights\n",
    "\n",
    "\n",
    "def translate(sentence,tokenizer_source, tokenizer_target, transformer):\n",
    "    predictions, attention = evaluate(\n",
    "        sentence,tokenizer_source, tokenizer_target, transformer\n",
    "    )\n",
    "\n",
    "    return predictions, attention\n",
    "\n",
    "\n",
    "predictions, attention = translate(\"dahua\",tokenizer_source,tokenizer_target,transformer)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "predictions, attention = translate(\"hikvision\",tokenizer_source,tokenizer_target,transformer)\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
